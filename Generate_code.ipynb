{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5mwGBz2OUwHp0no3WJXR2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmk4444/LLM/blob/main/Generate_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are different models to develop codes.\n",
        "- GPT-4 Turbo by OpenAI (General models)\n",
        "- Gemini Pro by Google AI (General models\n",
        "- Calude 2.1 by ANTHROP\\C (General models)\n",
        "- Github Coplit (Specialized Models)\n",
        "- Tabnine (Specialized Models)\n",
        "- Amazon CodeWhisperer (Specialized Models)\n",
        "- Replit Ghostwriter (Specialized Models)\n",
        "\n",
        "Specialized models can be utilized like extension."
      ],
      "metadata": {
        "id": "ySPU_tsDKWZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Prompt Schema**\n",
        "- You are a **PYTHON** expert.\n",
        "- I am developing a **WEB APPLICATION.**\n",
        "- You will help me with my problem.\n",
        "- I have the following **PYTHON STREAMLIT** code. Review the code and help me for **EXCEPTION HANDLING**. I want you to write the necessaary code lines or revise existing ones to let me *throw an error when the AI_Response is null, none or empty. *\n",
        "\n",
        "- Here IS MY CODE:\n",
        "-Code lines\n",
        "-Code lines\n",
        "-...\n",
        "\n",
        "- Now give me the entire code as I requested."
      ],
      "metadata": {
        "id": "lBVb1xiRM1ND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- Requirements.txt**\n"
      ],
      "metadata": {
        "id": "HX0hTK6pO_0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch requirements.txt\n",
        "!echo python-dotenv >> requirements.txt\n",
        "!echo openai >> requirements.txt\n",
        "!echo streamlit >> requirements.txt\n",
        "!echo google-generativeai >> requirements.txt\n",
        "!echo anthropic >> requirements.txt\n",
        "!echo cohere >> requirements.txt\n",
        "!echo replicate >> requirements.txt"
      ],
      "metadata": {
        "id": "3r51_xH9PCjK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **terminal / bash komutu**"
      ],
      "metadata": {
        "id": "0wcry4IjPFei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "WfDx49IcPD-x",
        "outputId": "56082b5d-6ae9-4518-852d-d172271ccfb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed anthropic-0.25.6 cohere-5.3.3 fastavro-1.9.4 gitdb-4.0.11 gitpython-3.1.43 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 httpx-sse-0.4.0 openai-1.23.6 pydeck-0.9.0b0 python-dotenv-1.0.1 replicate-0.25.2 smmap-5.0.1 streamlit-1.33.0 types-requests-2.31.0.20240406 watchdog-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import helper\n",
        "\n",
        "# We create session_state.messages if it is not available.\n",
        "if \"messages\" not in st.session_state:\n",
        "  st.session_state.messages = []\n",
        "  #st.session_state.messages.append({\"role\": \"system\", \"content\":\"Sen yardımsever bir asistansın.\"})\n",
        "\n",
        "def adjust_model_relations():\n",
        "  st.session_state.messages= []\n",
        "\n",
        "def send_message(prompt):\n",
        "  st.chat_message(\"user\").markdown(prompt)\n",
        "\n",
        "  if st.session_state.selected_model == \"GPT-4 Turbo\":\n",
        ""
      ],
      "metadata": {
        "id": "d-1S0lQtUKkR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}